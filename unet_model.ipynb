{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
            "    return await f(*args, **kwargs)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/cm/v3s0t3qx13dfvvg_xld0w1040000gn/T/ipykernel_7318/140902119.py\", line 1, in <module>\n",
            "    import torch\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/Users/junchishen/miniconda3/envs/dlpm_clean/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import random "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the Unet Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(卷积 => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_channels: 输入图像的通道数（RGB为3，灰度图为1）\n",
        "            n_classes: 输出分割的类别数\n",
        "        \"\"\"\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "\n",
        "        # 编码器（下采样路径）\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n",
        "        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n",
        "\n",
        "        # 解码器（上采样路径）\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.conv1 = DoubleConv(1024, 512)\n",
        "        \n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.conv2 = DoubleConv(512, 256)\n",
        "        \n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv3 = DoubleConv(256, 128)\n",
        "        \n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv4 = DoubleConv(128, 64)\n",
        "        \n",
        "        # 输出层\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "    def forward(self, x, verbose=False):\n",
        "        if verbose:\n",
        "            print(f\"输入形状: {x.shape}\")\n",
        "    \n",
        "        # 编码器\n",
        "        x1 = self.inc(x)\n",
        "        if verbose:\n",
        "            print(f\"inc 输出 (x1): {x1.shape}\")\n",
        "        \n",
        "        x2 = self.down1(x1)\n",
        "        if verbose:\n",
        "            print(f\"down1 输出 (x2): {x2.shape}\")\n",
        "        \n",
        "        x3 = self.down2(x2)\n",
        "        if verbose:\n",
        "            print(f\"down2 输出 (x3): {x3.shape}\")\n",
        "        \n",
        "        x4 = self.down3(x3)\n",
        "        if verbose:\n",
        "            print(f\"down3 输出 (x4): {x4.shape}\")\n",
        "        \n",
        "        x5 = self.down4(x4)\n",
        "        if verbose:\n",
        "            print(f\"down4 输出 (x5): {x5.shape}\")\n",
        "\n",
        "        # 解码器（带跳跃连接）\n",
        "        x = self.up1(x5)\n",
        "        if verbose:\n",
        "            print(f\"up1 输出: {x.shape}\")\n",
        "        \n",
        "        x = torch.cat([x4, x], dim=1)\n",
        "        if verbose:\n",
        "            print(f\"cat(x4, up1) 后: {x.shape}\")\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        if verbose:\n",
        "            print(f\"conv1 输出: {x.shape}\")\n",
        "\n",
        "        x = self.up2(x)\n",
        "        if verbose:\n",
        "            print(f\"up2 输出: {x.shape}\")\n",
        "        \n",
        "        x = torch.cat([x3, x], dim=1)\n",
        "        if verbose:\n",
        "            print(f\"cat(x3, up2) 后: {x.shape}\")\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        if verbose:\n",
        "            print(f\"conv2 输出: {x.shape}\")\n",
        "\n",
        "        x = self.up3(x)\n",
        "        if verbose:\n",
        "            print(f\"up3 输出: {x.shape}\")\n",
        "        \n",
        "        x = torch.cat([x2, x], dim=1)\n",
        "        if verbose:\n",
        "            print(f\"cat(x2, up3) 后: {x.shape}\")\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        if verbose:\n",
        "            print(f\"conv3 输出: {x.shape}\")\n",
        "\n",
        "        x = self.up4(x)\n",
        "        if verbose:\n",
        "            print(f\"up4 输出: {x.shape}\")\n",
        "        \n",
        "        x = torch.cat([x1, x], dim=1)\n",
        "        if verbose:\n",
        "            print(f\"cat(x1, up4) 后: {x.shape}\")\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        if verbose:\n",
        "            print(f\"conv4 输出: {x.shape}\")\n",
        "\n",
        "        # 输出\n",
        "        logits = self.outc(x)\n",
        "        if verbose:\n",
        "            print(f\"最终输出 (logits): {logits.shape}\")\n",
        "            print(f\"输出值范围: [{logits.min().item():.4f}, {logits.max().item():.4f}]\")\n",
        "        \n",
        "        return logits\n",
        "    # def forward(self, x):\n",
        "    #     # 编码器\n",
        "    #     x1 = self.inc(x)\n",
        "    #     x2 = self.down1(x1)\n",
        "    #     x3 = self.down2(x2)\n",
        "    #     x4 = self.down3(x3)\n",
        "    #     x5 = self.down4(x4)\n",
        "\n",
        "    #     # 解码器（带跳跃连接）\n",
        "    #     x = self.up1(x5)\n",
        "    #     x = torch.cat([x4, x], dim=1)\n",
        "    #     x = self.conv1(x)\n",
        "\n",
        "    #     x = self.up2(x)\n",
        "    #     x = torch.cat([x3, x], dim=1)\n",
        "    #     x = self.conv2(x)\n",
        "\n",
        "    #     x = self.up3(x)\n",
        "    #     x = torch.cat([x2, x], dim=1)\n",
        "    #     x = self.conv3(x)\n",
        "\n",
        "    #     x = self.up4(x)\n",
        "    #     x = torch.cat([x1, x], dim=1)\n",
        "    #     x = self.conv4(x)\n",
        "\n",
        "    #     # 输出\n",
        "    #     logits = self.outc(x)\n",
        "    #     return logits\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试：查看模型各层输出信息\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "input_tensor = input_tensor.to(device)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"UNet 模型各层输出信息\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor, verbose=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"最终输出形状: {output.shape}\")\n",
        "print(f\"最终输出值范围: [{output.min().item():.4f}, {output.max().item():.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial the mode \n",
        "\n",
        "# 对于 RGB 图像（3通道）进行二分类分割（1个输出通道）\n",
        "model = UNet(n_channels=3, n_classes=1)\n",
        "\n",
        "# 或者对于灰度图像（1通道）\n",
        "# model = UNet(n_channels=1, n_classes=1)\n",
        "\n",
        "# 如果有多个类别，比如分割成3类\n",
        "# model = UNet(n_channels=3, n_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 假设你有一张图像，需要转换为 tensor\n",
        "# 输入格式: (batch_size, channels, height, width)\n",
        "# 例如: (1, 3, 256, 256) 表示 1 张 256x256 的 RGB 图像\n",
        "\n",
        "\n",
        "\n",
        "# 加载图像\n",
        "# image = Image.open('your_image.jpg').convert('RGB')\n",
        "# 使用一个虚拟的数据集\n",
        "\n",
        "# 使用一个虚拟的数据集\n",
        "train_data = torch.randn(1, 3, 256, 256)\n",
        "train_label = torch.randn(1, 1, 256, 256)\n",
        "\n",
        "# 创建数据加载器\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(train_data, train_label),\n",
        "    batch_size=1, shuffle=True\n",
        ")\n",
        "\n",
        "# 这里不要再用 transforms 了，直接当输入即可\n",
        "input_tensor = train_data  # 形状已经是 (1, 3, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 将模型设置为评估模式\n",
        "model.eval()\n",
        "\n",
        "# 如果使用 GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "input_tensor = input_tensor.to(device)\n",
        "\n",
        "# 进行推理（不需要梯度计算）\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    # output 的形状: (batch_size, n_classes, height, width)\n",
        "    # 例如: (1, 1, 256, 256)\n",
        "    \n",
        "# 如果做二分类，可以用 sigmoid 激活\n",
        "prediction = torch.sigmoid(output)\n",
        "# 或者转换为二值掩码\n",
        "mask = (prediction > 0.5).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 创建模型\n",
        "model = UNet(n_channels=3, n_classes=1)\n",
        "model = model.to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.BCEWithLogitsLoss()  # 二分类\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "# 训练模式\n",
        "model.train()\n",
        "\n",
        "# 训练循环示例\n",
        "for epoch in range(num_epochs):\n",
        "    for images, masks in train_loader:  # 用上面定义的 train_loader\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        \n",
        "        # 前向传播\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # 计算损失\n",
        "        loss = criterion(outputs, masks)\n",
        "        \n",
        "        # 反向传播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forward process\n",
        "\n",
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "train_data = pd.read_csv('trainning_data_merged.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add noise "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Randomize 高斯噪音: $G_t$, 重尾因子 $S_{\\alpha}$ 以及一个 时间步 $t$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, T)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_noises\u001b[39m(dim, alpha, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    dim: 数据的维度 (例如图像的通道*高*宽)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    alpha: 尾部指数 (1 < alpha < 2)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "T = 4000\n",
        "t = random.randint(0, T)\n",
        "\n",
        "def generate_noises(dim, alpha, size=1):\n",
        "    \"\"\"\n",
        "    dim: 数据的维度 (例如图像的通道*高*宽)\n",
        "    alpha: 尾部指数 (1 < alpha < 2)\n",
        "    \"\"\"\n",
        "    # 1. 生成标准高斯噪音 (Gaussian Noise)\n",
        "    # 在 DLPM 中对应 G_t [cite: 108, 559]\n",
        "    gaussian_noise = np.random.normal(0, 1, (size, dim))\n",
        "    \n",
        "    # 2. 生成正稳定分布因子 (Positive Stable Variable A)\n",
        "    # 对应论文中的 A ~ S_{alpha/2, 1}(0, c_A) [cite: 108, 559]\n",
        "    # 使用 CMS 采样方法\n",
        "    def sample_positive_stable(a_val, num_samples):\n",
        "        # 这里的 a_val 对应论文中的 alpha/2 [cite: 108, 112]\n",
        "        half_alpha = a_val / 2\n",
        "        U = np.random.uniform(-np.pi/2, np.pi/2, num_samples)\n",
        "        W = np.random.exponential(1, num_samples)\n",
        "        \n",
        "        # 核心 CMS 公式\n",
        "        term1 = np.sin(half_alpha * (U + np.pi/2)) / (np.cos(U)**(1/half_alpha))\n",
        "        term2 = (np.cos(U - half_alpha * (U + np.pi/2)) / W)**((1 - half_alpha) / half_alpha)\n",
        "        A = (term1 * term2)\n",
        "        \n",
        "        # 乘以尺度常数 c_A = cos^{2/alpha}(pi * alpha / 4) [cite: 108, 552]\n",
        "        c_A = np.cos(np.pi * a_val / 4)**(1 / half_alpha)\n",
        "        return A * c_A\n",
        "\n",
        "    A_t = sample_positive_stable(alpha, size)\n",
        "    \n",
        "    # 3. 合成 DLPM 特有的重尾噪音\n",
        "    # epsilon = sqrt(A) * G \n",
        "    heavy_tailed_noise = np.sqrt(A_t)[:, np.newaxis] * gaussian_noise\n",
        "    \n",
        "    return gaussian_noise, A_t, heavy_tailed_noise\n",
        "\n",
        "# 示例：alpha=1.7 (论文中常用的值) [cite: 242, 402]\n",
        "alpha = 1.\n",
        "g_noise, a_factor, ht_noise = generate_noises(dim=252, alpha = alpha)\n",
        "# 其中的ht_noise 就是最后我们需要的噪音 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the noise if necessary "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the noise\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(ht_noise[0])  # 取第一行（因为 size=1）\n",
        "plt.xlabel('Dimension Index')\n",
        "plt.ylabel('Noise Value')\n",
        "plt.title(f'Heavy-Tailed Noise (alpha={alpha})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 也可以打印一些统计信息\n",
        "print(f\"ht_noise 形状: {ht_noise.shape}\")\n",
        "print(f\"均值: {ht_noise.mean():.4f}\")\n",
        "print(f\"标准差: {ht_noise.std():.4f}\")\n",
        "print(f\"最小值: {ht_noise.min():.4f}\")\n",
        "print(f\"最大值: {ht_noise.max():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cosine scheduler (input = T, t, $\\alpha$) = (output = $\\gamma_{1\\rightarrow t}$, $\\sigma_{1\\rightarrow t}$)\n",
        "\n",
        "这个里面对应的 T 指的是总的时间步骤，alpha 决定噪声的“重尾”程度。当 $\\alpha$ 越小（如 1.5），产生的噪声中偶尔会出现极大的“跳跃”值 9999。 \\\n",
        "\n",
        "$t$ 决定了公式里 $\\gamma_{1\\rightarrow t}$ 和 $\\sigma_{1\\rightarrow t}$ 到底取数组里的哪一个数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_dlpm_cosine_schedule(T, alpha, s=0.008):\n",
        "    \"\"\"\n",
        "    T: 总时间步 (Total time steps)\n",
        "    alpha: 尾部指数 (Tail index, 1 < alpha <= 2)\n",
        "    s: 偏移量，防止 t=0 时噪声过大\n",
        "    \"\"\"\n",
        "    # 1. 定义时间步序列\n",
        "    steps = np.arange(T + 1)\n",
        "    \n",
        "    # 2. 计算累积比例函数 f(t) [余弦曲线核心]\n",
        "    # 使用余弦平方函数，确保加噪过程平滑\n",
        "    ft = np.cos(((steps / T) + s) / (1 + s) * (np.pi / 2))**2\n",
        "    \n",
        "    # 3. 计算累积噪声控制序列 alpha_bar (在 DLPM 中对应缩放逻辑)\n",
        "    # alpha_bar 决定了原始信号保留的比例\n",
        "    alphas_bar = ft / ft[0]\n",
        "    \n",
        "    # 4. 根据 alpha_bar 计算 DLPM 特有的调度参数\n",
        "    # gamma_1_to_t: 位置/衰减系数 (控制原始数据 Y0 保留比例)\n",
        "    gamma_1_to_t = (alphas_bar)**(1 / alpha)\n",
        "    \n",
        "    # sigma_1_to_t: 尺度/噪声系数 (控制注入重尾噪声的强度)\n",
        "    # 基于尺度保持原则: gamma^alpha + sigma^alpha = 1\n",
        "    sigma_1_to_t = (1 - alphas_bar)**(1 / alpha)\n",
        "    \n",
        "    return gamma_1_to_t[1:], sigma_1_to_t[1:]\n",
        "\n",
        "# 使用示例\n",
        "T = 1000\n",
        "alpha = 1.7\n",
        "gamma_bar, sigma_bar = get_dlpm_cosine_schedule(T, alpha)\n",
        "# 这个里面的的下标 对应的是不同的t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get $Y_t$ with formula: \n",
        "\n",
        "$Y_t = \\gamma_{1\\rightarrow t}Y_0 + \\sigma_{1\\rightarrow t}\\overline{A}_t^{1/2}G_t$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_Y_t(Y_0, t, gamma_bar, sigma_bar, noise):\n",
        "    return gamma_bar[t] * Y_0 + sigma_bar[t] * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get final Y_t\n",
        "\n",
        "Y_0 = train_data\n",
        "\n",
        "Y_t = get_Y_t(Y_0, t, gamma_bar, sigma_bar,ht_noise)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlpm_clean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

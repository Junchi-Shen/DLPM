# path_simulators.py
# 
# è¿™æ˜¯ä¸€ä¸ªçº¯ç²¹çš„æ•°å­¦å’Œè®¡ç®—åº“ã€‚
# å®ƒåŒ…å«äº†æ‰€æœ‰è·¯å¾„ç”Ÿæˆçš„ "How-To"ã€‚

import torch
import numpy as np
import warnings
from arch import arch_model
import gc
from pathlib import Path
from Model.Diffusion_Model.diffusion_with_condition import GaussianDiffusion1D
from Model.Diffusion_Model.diffusion_dlpm import DLPMDiffusion1D
from Model.Diffusion_Model.Unet_with_condition import Unet1D
from Model.Diffusion_Model.condition_network import EnhancedConditionNetwork
from Data.Input_preparation import DataProcessor
import json
import joblib
# ==========================================================
# 1. GBM æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.2-GBM_MC_Generator.py)
# ==========================================================

def fit_garch_model(returns_data, use_student_t=True):
    """
    åœ¨ç»™å®šçš„æ”¶ç›Šç‡æ•°æ®ä¸Šæ‹ŸåˆGARCH(1,1)æ¨¡å‹ã€‚
    è¿™æ®µé€»è¾‘æ˜¯ä» 4.3-Garch_MC_Generator.py æå–å¹¶æ•´åˆåˆ°åº“ä¸­çš„ã€‚
    """
    print("ğŸ”„ æ­£åœ¨å®æ—¶æ‹Ÿåˆ GARCH(1,1) æ¨¡å‹...")
    # arch åº“ä¹ æƒ¯ä½¿ç”¨â€œç™¾åˆ†æ¯”â€å°ºåº¦çš„æ”¶ç›Šç‡
    returns = returns_data * 100.0 

    dist_name = 't' if use_student_t else 'normal'
    garch_model = arch_model(returns, vol='Garch', p=1, q=1, dist=dist_name)
    # disp='off' æ„å‘³ç€åœ¨æ‹Ÿåˆæ—¶ä¸æ‰“å°æ”¶æ•›ä¿¡æ¯
    garch_fit = garch_model.fit(disp='off')

    # --- æå–å‚æ•° ---
    # æ³¨æ„ omega çš„å°ºåº¦è½¬æ¢ï¼šä» ç™¾åˆ†æ¯”^2 è½¬æ¢ä¸º å°æ•°^2
    fitted_omega = float(garch_fit.params['omega']) / 10000.0
    
    # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ arch åº“çš„é”®å
    alpha_key = 'alpha[1]' if 'alpha[1]' in garch_fit.params.index else 'alpha'
    beta_key  = 'beta[1]'  if 'beta[1]'  in garch_fit.params.index else 'beta'
    
    fitted_alpha = float(garch_fit.params[alpha_key])
    fitted_beta  = float(garch_fit.params[beta_key])
    
    # åªæœ‰åœ¨ä½¿ç”¨ 't' åˆ†å¸ƒæ—¶æ‰å°è¯•æå– 'nu'
    fitted_nu = float(garch_fit.params['nu']) if 'nu' in garch_fit.params.index and use_student_t else np.nan

    FITTED_GARCH_PARAMS = {
        "omega": fitted_omega,
        "alpha": fitted_alpha,
        "beta":  fitted_beta,
        "nu":    fitted_nu
    }
    
    print("âœ… GARCH æ¨¡å‹æ‹Ÿåˆå®Œæˆ:")
    print(FITTED_GARCH_PARAMS)
    print(f"   Î±+Î² = {fitted_alpha + fitted_beta:.4f}")
    if np.isfinite(fitted_nu):
        print(f"   nu = {fitted_nu:.4f}")
        
    return FITTED_GARCH_PARAMS


def simulate_gbm(S0, r, sigma, T_days, n_simulations, n_steps_total=252):
    """
    æ‰§è¡Œå‡ ä½•å¸ƒæœ—è¿åŠ¨ (GBM) çš„è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ (å·²å¯¹é½)ã€‚
    
    æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ä¸ GARCH å¯¹é½ï¼Œä½¿ç”¨ NaN å¡«å……ï¼Œè€Œä¸æ˜¯å‰å‘å¡«å……ã€‚
    """
    T_years = T_days / 252.0
    dt = 1.0 / 252.0
    
    drift = (r - 0.5 * sigma**2) * dt
    diffusion = sigma * np.sqrt(dt)
    
    random_shocks = np.random.normal(0, 1, (T_days, n_simulations))
    log_returns = drift + diffusion * random_shocks
    log_paths = np.cumsum(log_returns, axis=0)
    
    log_paths = np.vstack([np.zeros(n_simulations), log_paths])
    log_paths += np.log(S0)
    
    price_paths_short = np.exp(log_paths).T # å½¢çŠ¶: (n_simulations, T_days + 1)
    
    # --- å…³é”®ï¼šä½¿ç”¨ NaN å¡«å……ä»¥å¯¹é½åˆ°å›ºå®šé•¿åº¦ 252 ---
    padded_paths = np.full((n_simulations, n_steps_total), np.nan)
    
    current_len = price_paths_short.shape[1]
    copy_len = min(current_len, n_steps_total) # é˜²æ­¢ T_days > 252
    
    padded_paths[:, :copy_len] = price_paths_short[:, :copy_len]
    
    # æœ€ç»ˆå½¢çŠ¶: (n_simulations, 1, n_steps_total)
    return padded_paths.reshape(n_simulations, 1, n_steps_total)

# ==========================================================
# 2. GARCH æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.3-Garch_MC_Generator.py)
# ==========================================================

def _draw_innovations(size, dist: str = "t", nu: float | None = None, rng: np.random.Generator | None = None):
    """GARCHçš„è¾…åŠ©å‡½æ•°ï¼šè¿”å›å½¢çŠ¶ä¸º `size` çš„åˆ›æ–°é¡¹ z_t"""
    rng = rng or np.random.default_rng()
    if dist.lower() == "t":
        if (nu is None) or (nu <= 2.0):
            warnings.warn("nu<=2 æˆ–æœªæä¾›ï¼Œåšå°¾ä»¿çœŸå›é€€ä¸ºæ­£æ€ã€‚")
            return rng.standard_normal(size)
        u = rng.standard_t(df=nu, size=size)
        z = u / np.sqrt(nu / (nu - 2.0)) # æ ‡å‡†åŒ– => Var(z)=1
        return z
    return rng.standard_normal(size)

def fit_garch_model(returns_data, use_student_t=True):
    """
    åœ¨ç»™å®šçš„æ”¶ç›Šç‡æ•°æ®ä¸Šæ‹ŸåˆGARCH(1,1)æ¨¡å‹ã€‚
    """
    print("ğŸ”„ æ­£åœ¨å®æ—¶æ‹Ÿåˆ GARCH(1,1) æ¨¡å‹...")
    returns = returns_data * 100.0  # arch ä¹ æƒ¯ç”¨â€œç™¾åˆ†æ¯”â€å°ºåº¦

    dist_name = 't' if use_student_t else 'normal'
    garch_model = arch_model(returns, vol='Garch', p=1, q=1, dist=dist_name)
    garch_fit = garch_model.fit(disp='off')

    # æå–å‚æ•°
    fitted_omega = float(garch_fit.params['omega']) / 10000.0 # è½¬å›å°æ•°^2
    alpha_key = 'alpha[1]' if 'alpha[1]' in garch_fit.params.index else 'alpha'
    beta_key  = 'beta[1]'  if 'beta[1]'  in garch_fit.params.index else 'beta'
    fitted_alpha = float(garch_fit.params[alpha_key])
    fitted_beta  = float(garch_fit.params[beta_key])
    fitted_nu    = float(garch_fit.params['nu']) if 'nu' in garch_fit.params.index else np.nan

    FITTED_GARCH_PARAMS = {
        "omega": fitted_omega, "alpha": fitted_alpha,
        "beta":  fitted_beta,  "nu":    fitted_nu
    }
    print("âœ… GARCH æ¨¡å‹æ‹Ÿåˆå®Œæˆ:")
    print(FITTED_GARCH_PARAMS)
    print(f"   Î±+Î² = {fitted_alpha + fitted_beta:.4f}")
    if np.isfinite(fitted_nu):
        print(f"   nu = {fitted_nu:.4f}")
        
    return FITTED_GARCH_PARAMS


def simulate_garch(
    S0, r, initial_vol_ann, T_days, n_simulations, n_steps_total, garch_params,
    innov_dist: str = "t", seed: int | None = 42
):
    """
    ä½¿ç”¨ GARCH(1,1) ç”Ÿæˆä»·æ ¼è·¯å¾„ã€‚
    è¿”å›ï¼š
      paths_out: (n_simulations, 1, n_steps_total)
      sigma2_out: (n_simulations, 1, T_days+1)  # æ³¨æ„ï¼šè¿™æ˜¯ *æœªå¡«å……* çš„
    """
    rng = np.random.default_rng(seed)
    T_days = int(T_days)
    n_simulations = int(n_simulations)
    n_steps_total = int(n_steps_total)

    price_paths = np.zeros((T_days + 1, n_simulations), dtype=np.float64)
    sigma2 = np.zeros((T_days + 1, n_simulations), dtype=np.float64)
    eps_prev = np.zeros((n_simulations,), dtype=np.float64)

    price_paths[0, :] = float(S0)
    sigma2[0, :] = (float(initial_vol_ann) / np.sqrt(252.0))**2

    omega = float(garch_params['omega'])
    alpha = float(garch_params['alpha'])
    beta  = float(garch_params['beta'])
    nu    = float(garch_params.get('nu', np.nan))

    if alpha + beta >= 1.0:
        warnings.warn(f"alpha+beta = {alpha+beta:.4f} >= 1.0", UserWarning)

    r_daily = float(r) / 252.0
    z_mat = _draw_innovations(size=(n_simulations, T_days), dist=innov_dist, nu=nu, rng=rng)

    for t in range(1, T_days + 1):
        sigma2[t, :] = omega + alpha * (eps_prev**2) + beta * sigma2[t-1, :]
        sigma2[t, :] = np.maximum(sigma2[t, :], 1e-18)

        sigma_t = np.sqrt(sigma2[t, :])
        z = z_mat[:, t-1]

        log_ret = (r_daily - 0.5 * sigma_t**2) + sigma_t * z
        price_paths[t, :] = price_paths[t-1, :] * np.exp(log_ret)
        eps_prev = sigma_t * z

    # å¯¹é½è¾“å‡ºï¼šä»·æ ¼è·¯å¾„ [n_sim, 1, n_steps_total]ï¼Œä¸è¶³éƒ¨åˆ†ä»¥ NaN
    paths_T = price_paths.T  # [n_sim, T_days+1]
    paths_out = np.full((n_simulations, n_steps_total), np.nan, dtype=np.float64)
    L = min(n_steps_total, paths_T.shape[1])
    paths_out[:, :L] = paths_T[:, :L]

    # æ–¹å·®è·¯å¾„ï¼šè¿”å›æœªå¡«å……çš„
    sig_out = sigma2.T  # [n_sim, T_days+1]
    
    return paths_out.reshape(n_simulations, 1, n_steps_total), \
           sig_out.reshape(n_simulations, 1, T_days + 1)


# ==========================================================
# 3. UNet/Diffusion æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.1-Unet_Generator_Optimized.py)
# ==========================================================

# è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ¨¡å‹
def load_diffusion_artifacts(
    model_dir: Path,
    processor_filename: str,
    model_filename: str,
    condition_network_filename: str | None, # <-- è®¾ä¸ºå¯é€‰
    unet_config: dict,      # <-- é‡å‘½åä¸º unet_config
    diffusion_config: dict,
    cond_net_config: dict | None, # <-- è®¾ä¸ºå¯é€‰
    device: str,
    use_dlpm: bool = False,  # <-- æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨DLPM
    dlpm_alpha: float = 1.7  # <-- æ–°å¢ï¼šDLPMçš„alphaå‚æ•°
):
    """
    åŠ è½½æ‰©æ•£ç”Ÿæˆæ‰€éœ€çš„æ‰€æœ‰äº§å‡ºç‰©ï¼š
    DataProcessor, ConditionNetwork (å¦‚æœæŒ‡å®š), U-Net, ä»¥åŠ Diffusion åŒ…è£…å™¨ã€‚
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ‰©æ•£æ¨¡å‹äº§å‡ºç‰©...")

    # --- 1. åŠ è½½ DataProcessor ---
    processor_path = model_dir / processor_filename
    if not processor_path.exists():
        raise FileNotFoundError(f"DataProcessor æ–‡ä»¶æœªæ‰¾åˆ°: {processor_path}")
    try:
        data_processor = joblib.load(processor_path)
        print(f"   âœ… DataProcessor å·²ä»ä»¥ä¸‹ä½ç½®åŠ è½½: {processor_path}")
        # æå–ç±»åˆ«æ•°é‡ï¼Œç”¨äºæ¡ä»¶ç½‘ç»œ
        num_countries = data_processor.num_countries if hasattr(data_processor, 'num_countries') and data_processor.num_countries else 1
        num_indices = data_processor.num_indices if hasattr(data_processor, 'num_indices') and data_processor.num_indices else 1
        print(f"      - æ£€æµ‹åˆ° {num_countries} ä¸ªå›½å®¶, {num_indices} ä¸ªæŒ‡æ•°ã€‚")
    except Exception as e:
        print(f"   âŒ åŠ è½½ DataProcessor æ—¶å‡ºé”™: {e}")
        raise

    # --- 2. åŠ è½½æ¡ä»¶ç½‘ç»œ (å¦‚æœæä¾›äº†æ–‡ä»¶å) ---
    condition_network = None
    cond_net_output_dim = 7 # é»˜è®¤ï¼šå¦‚æœæ²¡æœ‰æ¡ä»¶ç½‘ç»œï¼ŒU-Net æ¥æ”¶åŸå§‹ 7D æ¡ä»¶
    if condition_network_filename and cond_net_config: # éœ€è¦æ–‡ä»¶åå’Œé…ç½®
        cond_net_path = model_dir / condition_network_filename
        if not cond_net_path.exists():
            # å°è¯•å»æ‰å¯èƒ½çš„ '_all' åç¼€æŸ¥æ‰¾ (å…¼å®¹æ€§)
            cond_net_filename_base = condition_network_filename.replace('_all', '')
            cond_net_path = model_dir / cond_net_filename_base
            if not cond_net_path.exists():
                raise FileNotFoundError(f"ConditionNetwork æ–‡ä»¶æœªæ‰¾åˆ°äº {model_dir / condition_network_filename} æˆ– {cond_net_path}")

        print(f"   ğŸ”„ æ­£åœ¨ä»ä»¥ä¸‹ä½ç½®åŠ è½½ EnhancedConditionNetwork: {cond_net_path}")
        try:
            # ä½¿ç”¨ä» processor è·å–çš„ç±»åˆ«æ•°é‡å’Œé…ç½®ä¸­çš„ç»´åº¦æ¥åˆå§‹åŒ–ç½‘ç»œ
            cond_net_output_dim = cond_net_config.get('output_dim', 128) # è·å–è¾“å‡ºç»´åº¦
            condition_network = EnhancedConditionNetwork(
                num_countries=num_countries, # ä½¿ç”¨ä» processor è·å–çš„æ•°é‡
                num_indices=num_indices,   # ä½¿ç”¨ä» processor è·å–çš„æ•°é‡
                **cond_net_config        # ä¼ é€’é…ç½®ä¸­çš„å…¶ä»–ç»´åº¦å‚æ•°
            ).to(device)
            # åŠ è½½çŠ¶æ€å­—å…¸
            state_dict = torch.load(cond_net_path, map_location=device)
            # å¤„ç†å¯èƒ½çš„ DataParallel åŒ…è£…
            if isinstance(state_dict, dict) and any(k.startswith('module.') for k in state_dict):
                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            condition_network.load_state_dict(state_dict)
            condition_network.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            print(f"   âœ… EnhancedConditionNetwork åŠ è½½æˆåŠŸã€‚è¾“å‡ºç»´åº¦: {cond_net_output_dim}")
        except Exception as e:
            print(f"   âŒ åŠ è½½ EnhancedConditionNetwork æ—¶å‡ºé”™: {e}")
            raise
    else:
        print("   â„¹ï¸ æœªæŒ‡å®šæ¡ä»¶ç½‘ç»œæˆ–å…¶é…ç½®ï¼Œå°†ä¸ä½¿ç”¨ EnhancedConditionNetworkã€‚")
        # U-Net å°†æ¥æ”¶åŸå§‹ 7D æ¡ä»¶

    # --- 3. åŠ è½½ U-Net æ¨¡å‹ ---
    model_path = model_dir / model_filename
    if not model_path.exists():
        # å°è¯•å»æ‰å¯èƒ½çš„ '_all' åç¼€æŸ¥æ‰¾
        model_filename_base = model_filename.replace('_all', '')
        model_path = model_dir / model_filename_base
        if not model_path.exists():
           raise FileNotFoundError(f"U-Net æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°äº {model_dir / model_filename} æˆ– {model_path}")

    print(f"   ğŸ”„ æ­£åœ¨ä»ä»¥ä¸‹ä½ç½®åŠ è½½ U-Net æ¨¡å‹: {model_path}")
    try:
        unet_model_type = unet_config.get("model_type", "unet")
        unet_model_params = unet_config.get("model_params", {})
        # ** å…³é”®: U-Net çš„ cond_dim å¿…é¡»ä¸æ¡ä»¶ç½‘ç»œè¾“å‡ºåŒ¹é… (æˆ–ä¸º 7) **
        unet_cond_dim = cond_net_output_dim

        if unet_model_type == 'unet':
            model = Unet1D(cond_dim=unet_cond_dim, **unet_model_params).to(device)
        else:
            raise ValueError(f"æœªçŸ¥çš„ U-Net æ¨¡å‹ç±»å‹: {unet_model_type}")

        state_dict = torch.load(model_path, map_location=device)
        if isinstance(state_dict, dict) and any(k.startswith('module.') for k in state_dict):
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(state_dict)
        model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        print(f"   âœ… U-Net ({unet_model_type}) æ¨¡å‹åŠ è½½æˆåŠŸã€‚æœŸæœ›çš„ cond_dim: {unet_cond_dim}")
    except Exception as e:
        print(f"   âŒ åŠ è½½ U-Net æ¨¡å‹æ—¶å‡ºé”™: {e}")
        raise

    # --- 4. åˆå§‹åŒ– Diffusion åŒ…è£…å™¨ ---
    # ** å…³é”®: å°†åŠ è½½çš„ condition_network å®ä¾‹ (å¯èƒ½æ˜¯ None) ä¼ é€’ç»™æ‰©æ•£æ¨¡å‹ **
    if use_dlpm:
        print(f"   ğŸ”„ æ­£åœ¨åˆå§‹åŒ– DLPMDiffusion1D (alpha={dlpm_alpha})...")
        try:
            # DLPMç‰¹å®šçš„é…ç½®
            dlpm_config = {
                **diffusion_config,
                'alpha': dlpm_alpha,  # DLPMå‚æ•°
                'isotropic': True,   # DLPMå‚æ•°
                'rescale_timesteps': True,  # DLPMå‚æ•°
                'scale': 'scale_preserving',  # DLPMå‚æ•°
            }
            diffusion = DLPMDiffusion1D(
                model=model,
                condition_network=condition_network,
                **dlpm_config
            ).to(device)
            print(f"   âœ… DLPMDiffusion1D åˆå§‹åŒ–æˆåŠŸ {'å¸¦æœ‰' if condition_network else 'ä¸å¸¦'} æ¡ä»¶ç½‘ç»œã€‚")
        except Exception as e:
            print(f"   âŒ åˆå§‹åŒ– DLPMDiffusion1D æ—¶å‡ºé”™: {e}")
            raise
    else:
        print(f"   ğŸ”„ æ­£åœ¨åˆå§‹åŒ– GaussianDiffusion1D...")
        try:
            diffusion = GaussianDiffusion1D(
                model=model,                  # ä¼ é€’åŠ è½½çš„ U-Net
                condition_network=condition_network, # ä¼ é€’åŠ è½½çš„æ¡ä»¶ç½‘ç»œ (æˆ– None)
                **diffusion_config          # ä¼ é€’æ‰©æ•£è¿‡ç¨‹å‚æ•°
            ).to(device)
            print(f"   âœ… GaussianDiffusion1D åˆå§‹åŒ–æˆåŠŸ {'å¸¦æœ‰' if condition_network else 'ä¸å¸¦'} æ¡ä»¶ç½‘ç»œã€‚")
        except TypeError as e:
             if 'condition_network' in str(e):
                  print("   âŒ é”™è¯¯: GaussianDiffusion1D çš„ __init__ æ–¹æ³•ä¼¼ä¹ä¸æ”¯æŒ 'condition_network' å‚æ•°ã€‚")
                  print("       è¯·ç¡®ä¿ä½ ä½¿ç”¨çš„æ˜¯æ¥å—æ­¤å‚æ•°çš„ diffusion_with_condition.py ç‰ˆæœ¬ã€‚")
             raise
        except Exception as e:
             print(f"   âŒ åˆå§‹åŒ– GaussianDiffusion1D æ—¶å‡ºé”™: {e}")
             raise

    return diffusion, data_processor
# æ ¸å¿ƒç”Ÿæˆå‡½æ•° (æ‰¹é‡)
def _generate_paths_for_condition_batch(condition_batch, diffusion, total_paths, batch_size, device):
    """ä¸ºä¸€æ‰¹æ¡ä»¶åŒæ—¶ç”Ÿæˆè·¯å¾„ - æ ¸å¿ƒä¼˜åŒ–å‡½æ•°"""
    generated_paths = []
    
    for i, condition in enumerate(condition_batch):
        single_condition = condition.unsqueeze(0).to(device)
        
        paths_for_this_condition = []
        num_batches = (total_paths + batch_size - 1) // batch_size
        
        for _ in range(num_batches):
            num_remaining = total_paths - len(paths_for_this_condition)
            current_batch_size = min(batch_size, num_remaining)
            if current_batch_size <= 0:
                break
            
            with torch.no_grad():
                conditions_batch = single_condition.repeat(current_batch_size, 1)
                generated_batch = diffusion.sample(
                    batch_size=current_batch_size, 
                    cond_input=conditions_batch
                )
                paths_for_this_condition.append(generated_batch.cpu().numpy())
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
        
        full_ensemble = np.concatenate(paths_for_this_condition, axis=0)
        generated_paths.append(full_ensemble)
    
    return generated_paths

# æ ¼å¼åŒ–æ—¶é—´
def _format_time(seconds):
    if seconds < 60:
        return f"{seconds:.0f}ç§’"
    elif seconds < 3600:
        return f"{seconds/60:.1f}åˆ†é’Ÿ"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

# æ¨¡å¼ 1: å¹¶è¡Œä¼˜åŒ–
def run_diffusion_parallel_optimized(conditions, diffusion, gen_params, device):
    """å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬çš„è·¯å¾„ç”Ÿæˆå‡½æ•°"""
    from tqdm import tqdm
    import time

    total_paths = gen_params['num_paths_to_generate']
    batch_size = gen_params['generation_batch_size']
    condition_batch_size = gen_params.get('condition_batch_size', 8)
    
    num_conditions = conditions.shape[0]
    all_generated_paths = []
    
    print(f"ğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆè·¯å¾„...")
    print(f"   æ€»æ¡ä»¶æ•°: {num_conditions}, æ¯æ¡ä»¶è·¯å¾„æ•°: {total_paths}")
    print(f"   æ¡ä»¶æ‰¹å¤„ç†å¤§å°: {condition_batch_size}, ç”Ÿæˆæ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    num_condition_batches = (num_conditions + condition_batch_size - 1) // condition_batch_size
    start_time = time.time()
    
    for batch_idx in tqdm(range(num_condition_batches), desc="å¤„ç†æ¡ä»¶æ‰¹æ¬¡"):
        start_idx = batch_idx * condition_batch_size
        end_idx = min(start_idx + condition_batch_size, num_conditions)
        condition_batch = conditions[start_idx:end_idx]
        
        batch_paths = _generate_paths_for_condition_batch(
            condition_batch, diffusion, total_paths, batch_size, device
        )
        all_generated_paths.extend(batch_paths)
        
        if batch_idx % 5 == 0:
            gc.collect()
            if device.startswith('cuda'):
                torch.cuda.empty_cache()
        
        # å®æ—¶è¿›åº¦
        current_time = time.time()
        elapsed_time = current_time - start_time
        completed_conditions = end_idx
        if completed_conditions > 0:
            avg_time_per_condition = elapsed_time / completed_conditions
            remaining_conditions = num_conditions - completed_conditions
            estimated_remaining_time = remaining_conditions * avg_time_per_condition
            conditions_per_second = completed_conditions / elapsed_time
            
            if batch_idx % 10 == 0 or batch_idx == num_condition_batches - 1:
                print(f"\nğŸ“Š è¿›åº¦: {completed_conditions}/{num_conditions} ({completed_conditions/num_conditions*100:.1f}%)")
                print(f"   â±ï¸  å·²ç”¨æ—¶é—´: {_format_time(elapsed_time)}, é¢„è®¡å‰©ä½™: {_format_time(estimated_remaining_time)}")
                print(f"   ğŸš€ ç”Ÿæˆé€Ÿåº¦: {conditions_per_second:.2f} æ¡ä»¶/ç§’")

    total_time = time.time() - start_time
    print(f"\nâœ… è·¯å¾„ç”Ÿæˆå®Œæˆï¼æ€»ç”¨æ—¶: {_format_time(total_time)}")
    return all_generated_paths

# æ¨¡å¼ 2: è¶…çº§æ‰¹å¤„ç†
def run_diffusion_mega_batch(conditions, diffusion, gen_params, device):
    """è¶…çº§æ‰¹å¤„ç†ç‰ˆæœ¬ - æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡"""
    from tqdm import tqdm
    import time
    
    total_paths = gen_params['num_paths_to_generate']
    batch_size = gen_params['generation_batch_size']
    num_conditions = conditions.shape[0]
    all_generated_paths = []
    
    print(f"ğŸš€ å¼€å§‹è¶…çº§æ‰¹å¤„ç†ç”Ÿæˆ...")
    print(f"   æ€»æ¡ä»¶æ•°: {num_conditions}, æ¯æ¡ä»¶è·¯å¾„æ•°: {total_paths}, ç”Ÿæˆæ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    start_time = time.time()
    
    for i in tqdm(range(num_conditions), desc="å¤„ç†å¸‚åœºæ¡ä»¶"):
        single_condition = conditions[i:i+1].to(device)
        paths_for_this_condition = []
        num_batches = (total_paths + batch_size - 1) // batch_size
        
        for _ in tqdm(range(num_batches), desc=f"æ¡ä»¶ {i} æ‰¹æ¬¡", leave=False):
            num_remaining = total_paths - len(paths_for_this_condition)
            current_batch_size = min(batch_size, num_remaining)
            if current_batch_size <= 0:
                break
            
            with torch.no_grad():
                conditions_batch = single_condition.repeat(current_batch_size, 1)
                generated_batch = diffusion.sample(
                    batch_size=current_batch_size, 
                    cond_input=conditions_batch
                )
                paths_for_this_condition.append(generated_batch.cpu().numpy())
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
        
        full_ensemble = np.concatenate(paths_for_this_condition, axis=0)
        all_generated_paths.append(full_ensemble)
        
        # å®æ—¶è¿›åº¦
        if i % 10 == 0 or i == num_conditions - 1:
            current_time = time.time()
            elapsed_time = current_time - start_time
            completed_conditions = i + 1
            if completed_conditions > 0:
                avg_time_per_condition = elapsed_time / completed_conditions
                remaining_conditions = num_conditions - completed_conditions
                estimated_remaining_time = remaining_conditions * avg_time_per_condition
                conditions_per_second = completed_conditions / elapsed_time
                print(f"\nğŸ“Š è¿›åº¦: {completed_conditions}/{num_conditions} ({completed_conditions/num_conditions*100:.1f}%)")
                print(f"   â±ï¸  å·²ç”¨æ—¶é—´: {_format_time(elapsed_time)}, é¢„è®¡å‰©ä½™: {_format_time(estimated_remaining_time)}")
                print(f"   ğŸš€ ç”Ÿæˆé€Ÿåº¦: {conditions_per_second:.2f} æ¡ä»¶/ç§’")
    
    total_time = time.time() - start_time
    print(f"\nâœ… è·¯å¾„ç”Ÿæˆå®Œæˆï¼æ€»ç”¨æ—¶: {_format_time(total_time)}")
    return all_generated_paths
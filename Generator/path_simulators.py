# path_simulators.py
# 
# è¿™æ˜¯ä¸€ä¸ªçº¯ç²¹çš„æ•°å­¦å’Œè®¡ç®—åº“ã€‚
# å®ƒåŒ…å«äº†æ‰€æœ‰è·¯å¾„ç”Ÿæˆçš„ "How-To"ã€‚

import torch
import numpy as np
import warnings
from arch import arch_model
import gc
from pathlib import Path
from Model.Diffusion_Model.diffusion_with_condition import GaussianDiffusion1D
from Model.Diffusion_Model.diffusion_dlpm import DLPMDiffusion1D
from Model.Diffusion_Model.Unet_with_condition import Unet1D
from Model.Diffusion_Model.condition_network import EnhancedConditionNetwork
from Data.Input_preparation import DataProcessor
import json
import joblib
# ==========================================================
# 1. GBM æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.2-GBM_MC_Generator.py)
# ==========================================================

def fit_garch_model(returns_data, use_student_t=True):
    """
    åœ¨ç»™å®šçš„æ”¶ç›Šç‡æ•°æ®ä¸Šæ‹ŸåˆGARCH(1,1)æ¨¡å‹ã€‚
    è¿™æ®µé€»è¾‘æ˜¯ä» 4.3-Garch_MC_Generator.py æå–å¹¶æ•´åˆåˆ°åº“ä¸­çš„ã€‚
    """
    print("ğŸ”„ æ­£åœ¨å®æ—¶æ‹Ÿåˆ GARCH(1,1) æ¨¡å‹...")
    # arch åº“ä¹ æƒ¯ä½¿ç”¨â€œç™¾åˆ†æ¯”â€å°ºåº¦çš„æ”¶ç›Šç‡
    returns = returns_data * 100.0 

    dist_name = 't' if use_student_t else 'normal'
    garch_model = arch_model(returns, vol='Garch', p=1, q=1, dist=dist_name)
    # disp='off' æ„å‘³ç€åœ¨æ‹Ÿåˆæ—¶ä¸æ‰“å°æ”¶æ•›ä¿¡æ¯
    garch_fit = garch_model.fit(disp='off')

    # --- æå–å‚æ•° ---
    # æ³¨æ„ omega çš„å°ºåº¦è½¬æ¢ï¼šä» ç™¾åˆ†æ¯”^2 è½¬æ¢ä¸º å°æ•°^2
    fitted_omega = float(garch_fit.params['omega']) / 10000.0
    
    # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ arch åº“çš„é”®å
    alpha_key = 'alpha[1]' if 'alpha[1]' in garch_fit.params.index else 'alpha'
    beta_key  = 'beta[1]'  if 'beta[1]'  in garch_fit.params.index else 'beta'
    
    fitted_alpha = float(garch_fit.params[alpha_key])
    fitted_beta  = float(garch_fit.params[beta_key])
    
    # åªæœ‰åœ¨ä½¿ç”¨ 't' åˆ†å¸ƒæ—¶æ‰å°è¯•æå– 'nu'
    fitted_nu = float(garch_fit.params['nu']) if 'nu' in garch_fit.params.index and use_student_t else np.nan

    FITTED_GARCH_PARAMS = {
        "omega": fitted_omega,
        "alpha": fitted_alpha,
        "beta":  fitted_beta,
        "nu":    fitted_nu
    }
    
    print("âœ… GARCH æ¨¡å‹æ‹Ÿåˆå®Œæˆ:")
    print(FITTED_GARCH_PARAMS)
    print(f"   Î±+Î² = {fitted_alpha + fitted_beta:.4f}")
    if np.isfinite(fitted_nu):
        print(f"   nu = {fitted_nu:.4f}")
        
    return FITTED_GARCH_PARAMS


def simulate_gbm(S0, r, sigma, T_days, n_simulations, n_steps_total=252):
    """
    æ‰§è¡Œå‡ ä½•å¸ƒæœ—è¿åŠ¨ (GBM) çš„è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ (å·²å¯¹é½)ã€‚
    
    æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ä¸ GARCH å¯¹é½ï¼Œä½¿ç”¨ NaN å¡«å……ï¼Œè€Œä¸æ˜¯å‰å‘å¡«å……ã€‚
    """
    T_years = T_days / 252.0
    dt = 1.0 / 252.0
    
    drift = (r - 0.5 * sigma**2) * dt
    diffusion = sigma * np.sqrt(dt)
    
    random_shocks = np.random.normal(0, 1, (T_days, n_simulations))
    log_returns = drift + diffusion * random_shocks
    log_paths = np.cumsum(log_returns, axis=0)
    
    log_paths = np.vstack([np.zeros(n_simulations), log_paths])
    log_paths += np.log(S0)
    
    price_paths_short = np.exp(log_paths).T # å½¢çŠ¶: (n_simulations, T_days + 1)
    
    # --- å…³é”®ï¼šä½¿ç”¨ NaN å¡«å……ä»¥å¯¹é½åˆ°å›ºå®šé•¿åº¦ 252 ---
    padded_paths = np.full((n_simulations, n_steps_total), np.nan)
    
    current_len = price_paths_short.shape[1]
    copy_len = min(current_len, n_steps_total) # é˜²æ­¢ T_days > 252
    
    padded_paths[:, :copy_len] = price_paths_short[:, :copy_len]
    
    # æœ€ç»ˆå½¢çŠ¶: (n_simulations, 1, n_steps_total)
    return padded_paths.reshape(n_simulations, 1, n_steps_total)

# ==========================================================
# 2. GARCH æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.3-Garch_MC_Generator.py)
# ==========================================================

def _draw_innovations(size, dist: str = "t", nu: float | None = None, rng: np.random.Generator | None = None):
    """GARCHçš„è¾…åŠ©å‡½æ•°ï¼šè¿”å›å½¢çŠ¶ä¸º `size` çš„åˆ›æ–°é¡¹ z_t"""
    rng = rng or np.random.default_rng()
    if dist.lower() == "t":
        if (nu is None) or (nu <= 2.0):
            warnings.warn("nu<=2 æˆ–æœªæä¾›ï¼Œåšå°¾ä»¿çœŸå›é€€ä¸ºæ­£æ€ã€‚")
            return rng.standard_normal(size)
        u = rng.standard_t(df=nu, size=size)
        z = u / np.sqrt(nu / (nu - 2.0)) # æ ‡å‡†åŒ– => Var(z)=1
        return z
    return rng.standard_normal(size)

def fit_garch_model(returns_data, use_student_t=True):
    """
    åœ¨ç»™å®šçš„æ”¶ç›Šç‡æ•°æ®ä¸Šæ‹ŸåˆGARCH(1,1)æ¨¡å‹ã€‚
    """
    print("ğŸ”„ æ­£åœ¨å®æ—¶æ‹Ÿåˆ GARCH(1,1) æ¨¡å‹...")
    returns = returns_data * 100.0  # arch ä¹ æƒ¯ç”¨â€œç™¾åˆ†æ¯”â€å°ºåº¦

    dist_name = 't' if use_student_t else 'normal'
    garch_model = arch_model(returns, vol='Garch', p=1, q=1, dist=dist_name)
    garch_fit = garch_model.fit(disp='off')

    # æå–å‚æ•°
    fitted_omega = float(garch_fit.params['omega']) / 10000.0 # è½¬å›å°æ•°^2
    alpha_key = 'alpha[1]' if 'alpha[1]' in garch_fit.params.index else 'alpha'
    beta_key  = 'beta[1]'  if 'beta[1]'  in garch_fit.params.index else 'beta'
    fitted_alpha = float(garch_fit.params[alpha_key])
    fitted_beta  = float(garch_fit.params[beta_key])
    fitted_nu    = float(garch_fit.params['nu']) if 'nu' in garch_fit.params.index else np.nan

    FITTED_GARCH_PARAMS = {
        "omega": fitted_omega, "alpha": fitted_alpha,
        "beta":  fitted_beta,  "nu":    fitted_nu
    }
    print("âœ… GARCH æ¨¡å‹æ‹Ÿåˆå®Œæˆ:")
    print(FITTED_GARCH_PARAMS)
    print(f"   Î±+Î² = {fitted_alpha + fitted_beta:.4f}")
    if np.isfinite(fitted_nu):
        print(f"   nu = {fitted_nu:.4f}")
        
    return FITTED_GARCH_PARAMS


def simulate_garch(
    S0, r, initial_vol_ann, T_days, n_simulations, n_steps_total, garch_params,
    innov_dist: str = "t", seed: int | None = 42
):
    """
    ä½¿ç”¨ GARCH(1,1) ç”Ÿæˆä»·æ ¼è·¯å¾„ã€‚
    è¿”å›ï¼š
      paths_out: (n_simulations, 1, n_steps_total)
      sigma2_out: (n_simulations, 1, T_days+1)  # æ³¨æ„ï¼šè¿™æ˜¯ *æœªå¡«å……* çš„
    """
    rng = np.random.default_rng(seed)
    T_days = int(T_days)
    n_simulations = int(n_simulations)
    n_steps_total = int(n_steps_total)

    price_paths = np.zeros((T_days + 1, n_simulations), dtype=np.float64)
    sigma2 = np.zeros((T_days + 1, n_simulations), dtype=np.float64)
    eps_prev = np.zeros((n_simulations,), dtype=np.float64)

    price_paths[0, :] = float(S0)
    sigma2[0, :] = (float(initial_vol_ann) / np.sqrt(252.0))**2

    omega = float(garch_params['omega'])
    alpha = float(garch_params['alpha'])
    beta  = float(garch_params['beta'])
    nu    = float(garch_params.get('nu', np.nan))

    if alpha + beta >= 1.0:
        warnings.warn(f"alpha+beta = {alpha+beta:.4f} >= 1.0", UserWarning)

    r_daily = float(r) / 252.0
    z_mat = _draw_innovations(size=(n_simulations, T_days), dist=innov_dist, nu=nu, rng=rng)

    for t in range(1, T_days + 1):
        sigma2[t, :] = omega + alpha * (eps_prev**2) + beta * sigma2[t-1, :]
        sigma2[t, :] = np.maximum(sigma2[t, :], 1e-18)

        sigma_t = np.sqrt(sigma2[t, :])
        z = z_mat[:, t-1]

        log_ret = (r_daily - 0.5 * sigma_t**2) + sigma_t * z
        price_paths[t, :] = price_paths[t-1, :] * np.exp(log_ret)
        eps_prev = sigma_t * z

    # å¯¹é½è¾“å‡ºï¼šä»·æ ¼è·¯å¾„ [n_sim, 1, n_steps_total]ï¼Œä¸è¶³éƒ¨åˆ†ä»¥ NaN
    paths_T = price_paths.T  # [n_sim, T_days+1]
    paths_out = np.full((n_simulations, n_steps_total), np.nan, dtype=np.float64)
    L = min(n_steps_total, paths_T.shape[1])
    paths_out[:, :L] = paths_T[:, :L]

    # æ–¹å·®è·¯å¾„ï¼šè¿”å›æœªå¡«å……çš„
    sig_out = sigma2.T  # [n_sim, T_days+1]
    
    return paths_out.reshape(n_simulations, 1, n_steps_total), \
           sig_out.reshape(n_simulations, 1, T_days + 1)


# ==========================================================
# 3. UNet/Diffusion æ¨¡æ‹Ÿå™¨ (æ¥è‡ª 4.1-Unet_Generator_Optimized.py)
# ==========================================================

# è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ¨¡å‹
def load_diffusion_artifacts(
    model_dir: Path,
    processor_filename: str,
    model_filename: str,
    condition_network_filename: str | None,
    unet_config: dict,
    diffusion_config: dict,
    cond_net_config: dict | None,
    device: str,
    use_dlpm: bool = False,
    dlpm_alpha: float = 1.7 
):
    """
    è‡ªé€‚åº”ç»´åº¦åŠ è½½å™¨ï¼šè‡ªåŠ¨ä»æƒé‡æ¢æµ‹ç»´åº¦ï¼Œå®ç°å…¨å±€æ¨¡å‹å¯¹å±€éƒ¨èµ„äº§çš„â€˜è‡ªç”±ç”Ÿæˆâ€™ã€‚
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ‰©æ•£æ¨¡å‹äº§å‡ºç‰©...")

    # --- 1. åŠ è½½ DataProcessor (ç”¨äºé€†å‘è½¬æ¢ï¼Œä¸ç”¨äºå†³å®šç»´åº¦) ---
    processor_path = model_dir / processor_filename
    data_processor = joblib.load(processor_path)

    # --- 2. åŠ¨æ€ç»´åº¦æ¢æµ‹ (è§£å†³ Size Mismatch) ---
    condition_network = None
    if condition_network_filename and cond_net_config:
        cond_net_path = model_dir / condition_network_filename
        # å…ˆåŠ è½½æƒé‡å­—å…¸ä»¥æ¢æµ‹è®­ç»ƒæ—¶çš„â€œèˆå°å¤§å°â€
        state_dict_cond = torch.load(cond_net_path, map_location=device)
        state_dict_cond = {k.replace('module.', ''): v for k, v in state_dict_cond.items()}
        
        # æ ¸å¿ƒï¼šç›´æ¥ä»æƒé‡çŸ©é˜µçš„ shape æå–ç»´åº¦ (å¦‚ 7 å’Œ 18)
        trained_countries = state_dict_cond['country_embedding.weight'].shape[0]
        trained_indices = state_dict_cond['index_embedding.weight'].shape[0]
        
        print(f"      - ğŸš€ æ¨¡å‹è‡ªç”±åŒ–ï¼šè‡ªåŠ¨å¯¹é½è®­ç»ƒç»´åº¦ ({trained_countries} å›½å®¶, {trained_indices} æŒ‡æ•°)")

        condition_network = EnhancedConditionNetwork(
            num_countries=trained_countries, 
            num_indices=trained_indices,
            **cond_net_config
        ).to(device)
        
        condition_network.load_state_dict(state_dict_cond)
        condition_network.eval()

    # --- 3. åˆå§‹åŒ–æ¨¡å‹ç»“æ„ (U-Net) ---
    model_path = model_dir / model_filename
    unet_cond_dim = cond_net_config['output_dim'] if cond_net_config else 7
    model = Unet1D(cond_dim=unet_cond_dim, **unet_config.get("model_params", {})).to(device)

    # --- 4. æ„å»º Diffusion åŒ…è£…å™¨ ---
    if use_dlpm:
        diffusion = DLPMDiffusion1D(model=model, condition_network=condition_network, **diffusion_config).to(device)
    else:
        diffusion = GaussianDiffusion1D(model=model, condition_network=condition_network, **diffusion_config).to(device)

    # --- 5. æƒé‡åŠ è½½ä¸å¯¹è±¡å¯¹é½ (ä¿®å¤ç‰ˆ) ---
    print(f"   ğŸ”„ æ­£åœ¨ä»æƒé‡æ–‡ä»¶åŒæ­¥ç‰©ç†å‚æ•°: {model_path.name}")
    state_dict = torch.load(model_path, map_location=device)
    
    # è‡ªåŠ¨æ¸…æ´— DataParallel å‰ç¼€
    state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}

    # --- å…³é”®ä¿®æ”¹ç‚¹ï¼šåˆ†å±‚åŠ è½½ ---
    # 1. æå–å¹¶åŠ è½½ U-Net å†…éƒ¨æƒé‡
    # å¦‚æœ pth é‡Œå·²ç»æ˜¯ model.xxxx æ ¼å¼ï¼Œç›´æ¥åŠ è½½ï¼›
    # å¦‚æœæ˜¯ init_conv æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬å¯¹åº”åˆ° diffusion.model ä¸Š
    if any(k.startswith('init_conv') for k in state_dict):
        # è¯´æ˜ pth ä¿å­˜çš„æ˜¯ Unet å†…éƒ¨æƒé‡ï¼Œå°†å…¶æ‰‹åŠ¨æŒ‚è½½åˆ° diffusion.model
        diffusion.model.load_state_dict(state_dict, strict=False)
        print("      - âœ… å·²æˆåŠŸåŒæ­¥ U-Net ç½‘ç»œæƒé‡")
    else:
        # è¯´æ˜ pth ä¿å­˜çš„æ˜¯å®Œæ•´çš„ Diffusion å¯¹è±¡æƒé‡
        diffusion.load_state_dict(state_dict, strict=False)
        print("      - âœ… å·²æˆåŠŸåŒæ­¥å…¨é‡æ¨¡å‹æƒé‡")

    # 2. æå–å¹¶åŒæ­¥ Alpha (æ ¸å¿ƒç‰©ç†å‚æ•°)
    if 'learnable_alpha' in state_dict:
        trained_alpha = state_dict['learnable_alpha'].item()
        diffusion.learnable_alpha.data = torch.tensor(float(trained_alpha)).to(device)
        
        if use_dlpm:
            # å¼ºåˆ¶åŒæ­¥ç»™åº•å±‚ç‰©ç†å¼•æ“
            diffusion.generative_process.dlpm.alpha = trained_alpha
            diffusion.generative_process.dlpm.A = None # å¼ºåˆ¶é‡ç½®çŸ©é˜µç¼“å­˜
            diffusion.generative_process.dlpm.Sigmas = None
            print(f"      - ğŸ¯ ç‰©ç†å¯¹é½ï¼šå·²è‡ªåŠ¨æå– Alpha = {trained_alpha:.6f}")
    
    diffusion.eval()
    return diffusion, data_processor
# æ ¸å¿ƒç”Ÿæˆå‡½æ•° (æ‰¹é‡)
def _generate_paths_for_condition_batch(condition_batch, diffusion, total_paths, batch_size, device):
    """ä¸ºä¸€æ‰¹æ¡ä»¶åŒæ—¶ç”Ÿæˆè·¯å¾„ - æ ¸å¿ƒä¼˜åŒ–å‡½æ•°"""
    generated_paths = []
    
    for i, condition in enumerate(condition_batch):
        single_condition = condition.unsqueeze(0).to(device)
        
        paths_for_this_condition = []
        num_batches = (total_paths + batch_size - 1) // batch_size
        
        for _ in range(num_batches):
            num_remaining = total_paths - len(paths_for_this_condition)
            current_batch_size = min(batch_size, num_remaining)
            if current_batch_size <= 0:
                break
            
            with torch.no_grad():
                conditions_batch = single_condition.repeat(current_batch_size, 1)
                generated_batch = diffusion.sample(
                    batch_size=current_batch_size, 
                    cond_input=conditions_batch
                )
                paths_for_this_condition.append(generated_batch.cpu().numpy())
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
        
        full_ensemble = np.concatenate(paths_for_this_condition, axis=0)
        generated_paths.append(full_ensemble)
    
    return generated_paths

# æ ¼å¼åŒ–æ—¶é—´
def _format_time(seconds):
    if seconds < 60:
        return f"{seconds:.0f}ç§’"
    elif seconds < 3600:
        return f"{seconds/60:.1f}åˆ†é’Ÿ"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

# æ¨¡å¼ 1: å¹¶è¡Œä¼˜åŒ–
def run_diffusion_parallel_optimized(conditions, diffusion, gen_params, device):
    """å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬çš„è·¯å¾„ç”Ÿæˆå‡½æ•°"""
    from tqdm import tqdm
    import time

    total_paths = gen_params['num_paths_to_generate']
    batch_size = gen_params['generation_batch_size']
    condition_batch_size = gen_params.get('condition_batch_size', 8)
    
    num_conditions = conditions.shape[0]
    all_generated_paths = []
    
    print(f"ğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆè·¯å¾„...")
    print(f"   æ€»æ¡ä»¶æ•°: {num_conditions}, æ¯æ¡ä»¶è·¯å¾„æ•°: {total_paths}")
    print(f"   æ¡ä»¶æ‰¹å¤„ç†å¤§å°: {condition_batch_size}, ç”Ÿæˆæ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    num_condition_batches = (num_conditions + condition_batch_size - 1) // condition_batch_size
    start_time = time.time()
    
    for batch_idx in tqdm(range(num_condition_batches), desc="å¤„ç†æ¡ä»¶æ‰¹æ¬¡"):
        start_idx = batch_idx * condition_batch_size
        end_idx = min(start_idx + condition_batch_size, num_conditions)
        condition_batch = conditions[start_idx:end_idx]
        
        batch_paths = _generate_paths_for_condition_batch(
            condition_batch, diffusion, total_paths, batch_size, device
        )
        all_generated_paths.extend(batch_paths)
        
        if batch_idx % 5 == 0:
            gc.collect()
            if device.startswith('cuda'):
                torch.cuda.empty_cache()
        
        # å®æ—¶è¿›åº¦
        current_time = time.time()
        elapsed_time = current_time - start_time
        completed_conditions = end_idx
        if completed_conditions > 0:
            avg_time_per_condition = elapsed_time / completed_conditions
            remaining_conditions = num_conditions - completed_conditions
            estimated_remaining_time = remaining_conditions * avg_time_per_condition
            conditions_per_second = completed_conditions / elapsed_time
            
            if batch_idx % 10 == 0 or batch_idx == num_condition_batches - 1:
                print(f"\nğŸ“Š è¿›åº¦: {completed_conditions}/{num_conditions} ({completed_conditions/num_conditions*100:.1f}%)")
                print(f"   â±ï¸  å·²ç”¨æ—¶é—´: {_format_time(elapsed_time)}, é¢„è®¡å‰©ä½™: {_format_time(estimated_remaining_time)}")
                print(f"   ğŸš€ ç”Ÿæˆé€Ÿåº¦: {conditions_per_second:.2f} æ¡ä»¶/ç§’")

    total_time = time.time() - start_time
    print(f"\nâœ… è·¯å¾„ç”Ÿæˆå®Œæˆï¼æ€»ç”¨æ—¶: {_format_time(total_time)}")
    return all_generated_paths

# æ¨¡å¼ 2: è¶…çº§æ‰¹å¤„ç†
def run_diffusion_mega_batch(conditions, diffusion, gen_params, device):
    """è¶…çº§æ‰¹å¤„ç†ç‰ˆæœ¬ - æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡"""
    from tqdm import tqdm
    import time
    
    total_paths = gen_params['num_paths_to_generate']
    batch_size = gen_params['generation_batch_size']
    num_conditions = conditions.shape[0]
    all_generated_paths = []
    sampling_steps = gen_params.get('sampling_timesteps', 200)
    
    print(f"ğŸš€ å¼€å§‹è¶…çº§æ‰¹å¤„ç†ç”Ÿæˆ...")
    print(f"   æ€»æ¡ä»¶æ•°: {num_conditions}, æ¯æ¡ä»¶è·¯å¾„æ•°: {total_paths}, ç”Ÿæˆæ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    start_time = time.time()
    
    for i in tqdm(range(num_conditions), desc="å¤„ç†å¸‚åœºæ¡ä»¶"):
        single_condition = conditions[i:i+1].to(device)
        paths_for_this_condition = []
        num_batches = (total_paths + batch_size - 1) // batch_size
        
        for _ in tqdm(range(num_batches), desc=f"æ¡ä»¶ {i} æ‰¹æ¬¡", leave=False):
            num_remaining = total_paths - len(paths_for_this_condition)
            current_batch_size = min(batch_size, num_remaining)
            if current_batch_size <= 0:
                break
            
            with torch.no_grad():
                conditions_batch = single_condition.repeat(current_batch_size, 1)
                generated_batch = diffusion.sample(
                    batch_size=current_batch_size, 
                    cond_input=conditions_batch,
                    sampling_timesteps = sampling_steps
                )
                paths_for_this_condition.append(generated_batch.cpu().numpy())
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
        
        full_ensemble = np.concatenate(paths_for_this_condition, axis=0)
        all_generated_paths.append(full_ensemble)
        
        # å®æ—¶è¿›åº¦
        if i % 10 == 0 or i == num_conditions - 1:
            current_time = time.time()
            elapsed_time = current_time - start_time
            completed_conditions = i + 1
            if completed_conditions > 0:
                avg_time_per_condition = elapsed_time / completed_conditions
                remaining_conditions = num_conditions - completed_conditions
                estimated_remaining_time = remaining_conditions * avg_time_per_condition
                conditions_per_second = completed_conditions / elapsed_time
                print(f"\nğŸ“Š è¿›åº¦: {completed_conditions}/{num_conditions} ({completed_conditions/num_conditions*100:.1f}%)")
                print(f"   â±ï¸  å·²ç”¨æ—¶é—´: {_format_time(elapsed_time)}, é¢„è®¡å‰©ä½™: {_format_time(estimated_remaining_time)}")
                print(f"   ğŸš€ ç”Ÿæˆé€Ÿåº¦: {conditions_per_second:.2f} æ¡ä»¶/ç§’")
    
    total_time = time.time() - start_time
    print(f"\nâœ… è·¯å¾„ç”Ÿæˆå®Œæˆï¼æ€»ç”¨æ—¶: {_format_time(total_time)}")
    return all_generated_paths
        
    

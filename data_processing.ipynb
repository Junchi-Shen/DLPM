{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a658ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import logging\n",
    "import torch\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec3c37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('trainning_data_merged.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b62a3edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract_calendar_days</th>\n",
       "      <th>expected_trading_days</th>\n",
       "      <th>actual_trading_days</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_price</th>\n",
       "      <th>price_series</th>\n",
       "      <th>volatility</th>\n",
       "      <th>risk_free_rate</th>\n",
       "      <th>ticker</th>\n",
       "      <th>country</th>\n",
       "      <th>asset_underlying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>6139.29</td>\n",
       "      <td>[6139.29, 6168.66, 6252.08, 6109.29, 6336.63, ...</td>\n",
       "      <td>0.212546</td>\n",
       "      <td>0.047990</td>\n",
       "      <td>852</td>\n",
       "      <td>China</td>\n",
       "      <td>CSI1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>6168.66</td>\n",
       "      <td>[6168.66, 6252.08, 6109.29, 6336.63, 6465.73, ...</td>\n",
       "      <td>0.212604</td>\n",
       "      <td>0.047970</td>\n",
       "      <td>852</td>\n",
       "      <td>China</td>\n",
       "      <td>CSI1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>6252.08</td>\n",
       "      <td>[6252.08, 6109.29, 6336.63, 6465.73, 6568.64, ...</td>\n",
       "      <td>0.210737</td>\n",
       "      <td>0.047930</td>\n",
       "      <td>852</td>\n",
       "      <td>China</td>\n",
       "      <td>CSI1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>6109.29</td>\n",
       "      <td>[6109.29, 6336.63, 6465.73, 6568.64, 6502.07, ...</td>\n",
       "      <td>0.210879</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>852</td>\n",
       "      <td>China</td>\n",
       "      <td>CSI1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>6336.63</td>\n",
       "      <td>[6336.63, 6465.73, 6568.64, 6502.07, 6642.61, ...</td>\n",
       "      <td>0.212102</td>\n",
       "      <td>0.048465</td>\n",
       "      <td>852</td>\n",
       "      <td>China</td>\n",
       "      <td>CSI1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contract_calendar_days  expected_trading_days  actual_trading_days  \\\n",
       "0                      30                     20                   22   \n",
       "1                      30                     20                   21   \n",
       "2                      30                     20                   20   \n",
       "3                      30                     20                   21   \n",
       "4                      30                     20                   20   \n",
       "\n",
       "   start_date  start_price                                       price_series  \\\n",
       "0  2015-01-14      6139.29  [6139.29, 6168.66, 6252.08, 6109.29, 6336.63, ...   \n",
       "1  2015-01-15      6168.66  [6168.66, 6252.08, 6109.29, 6336.63, 6465.73, ...   \n",
       "2  2015-01-16      6252.08  [6252.08, 6109.29, 6336.63, 6465.73, 6568.64, ...   \n",
       "3  2015-01-19      6109.29  [6109.29, 6336.63, 6465.73, 6568.64, 6502.07, ...   \n",
       "4  2015-01-20      6336.63  [6336.63, 6465.73, 6568.64, 6502.07, 6642.61, ...   \n",
       "\n",
       "   volatility  risk_free_rate ticker country asset_underlying  \n",
       "0    0.212546        0.047990    852   China          CSI1000  \n",
       "1    0.212604        0.047970    852   China          CSI1000  \n",
       "2    0.210737        0.047930    852   China          CSI1000  \n",
       "3    0.210879        0.047900    852   China          CSI1000  \n",
       "4    0.212102        0.048465    852   China          CSI1000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_mock = train_data.head()\n",
    "training_data_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "214ae237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中位长度: 64.0  80% 样本长度 <= 243.0  90% 样本长度 <= 252.0\n",
      "建议的序列长度 L = 256\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = train_data[\"price_series\"].apply(lambda x: len(eval(x)))\n",
    "p50 = np.percentile(lengths, 50)  # 中位数\n",
    "p80 = np.percentile(lengths, 80)\n",
    "p90 = np.percentile(lengths, 90)\n",
    "\n",
    "print(\"中位长度:\", p50, \" 80% 样本长度 <=\", p80, \" 90% 样本长度 <=\", p90)\n",
    "\n",
    "# 比如我们想覆盖 90% 的样本：\n",
    "L = int(p90)\n",
    "# 再四舍五入到一个好看一点的数，比如最近的 8 或 16 的倍数：\n",
    "L = int(np.ceil(L / 8.0) * 8)\n",
    "print(\"建议的序列长度 L =\", L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3618b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_mock['price_series'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "810bc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"volatility_scale\": 0.1,        # 收益率缩放因子（比如0.1或0.2，按你原来的设置来）\n",
    "    \"input_sequence_length\": 256,    # 每条样本的时间序列长度\n",
    "    \"base_trading_days\": 252,       # 一年交易日数（用来归一化价格）\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1050ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据准备完成：\n",
      "X_t 形状: torch.Size([5, 7])\n",
      "y_t 形状: torch.Size([5, 1, 256])\n",
      "mask_t 形状: torch.Size([5, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ===================== 2. 简单的工具函数 =====================\n",
    "\n",
    "def encode_to_ids(series):\n",
    "    \"\"\"\n",
    "    把一列字符串/类别，简单编码成 0,1,2,...\n",
    "    \"\"\"\n",
    "    codes, uniques = pd.factorize(series.astype(str))\n",
    "    return codes.astype(np.int32)\n",
    "\n",
    "# ===== 标准化相关：用 dict 存参数，而不是 class =====\n",
    "\n",
    "def fit_scaler(X, outlier_threshold=3.0):\n",
    "    \"\"\"\n",
    "    拟合一个“增强标准化器”，返回：\n",
    "    - X_scaled：变换后的特征\n",
    "    - scaler: 里面存了 RobustScaler、每一列的 PowerTransformer 等\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # 1) 先做 RobustScaler（对极端值比较鲁棒）\n",
    "    robust = RobustScaler()\n",
    "    X_r = robust.fit_transform(X)\n",
    "\n",
    "    # 2) 用 3σ 规则截断极端值\n",
    "    X_c = X_r.copy()\n",
    "    for i in range(n_features):\n",
    "        col = X_r[:, i]\n",
    "        mean = col.mean()\n",
    "        std = col.std()\n",
    "        lower = mean - outlier_threshold * std\n",
    "        upper = mean + outlier_threshold * std\n",
    "        X_c[:, i] = np.clip(col, lower, upper)\n",
    "\n",
    "    # 3) 每一列单独做 PowerTransformer(yeo-johnson, 带 standardize)\n",
    "    transformers = []\n",
    "    X_out = np.zeros_like(X_c)\n",
    "    for i in range(n_features):\n",
    "        pt = PowerTransformer(method=\"yeo-johnson\", standardize=True)\n",
    "        col = X_c[:, i].reshape(-1, 1)\n",
    "        X_out[:, i] = pt.fit_transform(col).ravel()\n",
    "        transformers.append(pt)\n",
    "\n",
    "    scaler = {\n",
    "        \"robust\": robust,\n",
    "        \"transformers\": transformers,\n",
    "        \"n_features\": n_features,\n",
    "        \"outlier_threshold\": outlier_threshold,\n",
    "    }\n",
    "    return X_out, scaler\n",
    "\n",
    "\n",
    "def transform_with_scaler(X, scaler):\n",
    "    \"\"\"\n",
    "    用已经拟合好的 scaler 去变换新的 X\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    robust = scaler[\"robust\"]\n",
    "    transformers = scaler[\"transformers\"]\n",
    "    n_features = scaler[\"n_features\"]\n",
    "    outlier_threshold = scaler[\"outlier_threshold\"]\n",
    "\n",
    "    # 1) RobustScaler\n",
    "    X_r = robust.transform(X)\n",
    "\n",
    "    # 2) 截断极端值\n",
    "    X_c = X_r.copy()\n",
    "    for i in range(n_features):\n",
    "        col = X_r[:, i]\n",
    "        mean = col.mean()\n",
    "        std = col.std()\n",
    "        lower = mean - outlier_threshold * std\n",
    "        upper = mean + outlier_threshold * std\n",
    "        X_c[:, i] = np.clip(col, lower, upper)\n",
    "\n",
    "    # 3) PowerTransformer\n",
    "    X_out = np.zeros_like(X_c)\n",
    "    for i in range(n_features):\n",
    "        col = X_c[:, i].reshape(-1, 1)\n",
    "        X_out[:, i] = transformers[i].transform(col).ravel()\n",
    "\n",
    "    return X_out\n",
    "\n",
    "\n",
    "def inverse_transform(X, scaler):\n",
    "    \"\"\"\n",
    "    从标准化空间反变换回原始特征空间\n",
    "    （这里只在从预测结果还原价格时会用到）\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    robust = scaler[\"robust\"]\n",
    "    transformers = scaler[\"transformers\"]\n",
    "    n_features = scaler[\"n_features\"]\n",
    "\n",
    "    X_inv = np.zeros_like(X)\n",
    "    for i in range(n_features):\n",
    "        col = X[:, i].reshape(-1, 1)\n",
    "        X_inv[:, i] = transformers[i].inverse_transform(col).ravel()\n",
    "\n",
    "    X_inv = robust.inverse_transform(X_inv)\n",
    "    return X_inv\n",
    "\n",
    "\n",
    "# ===================== 3. 处理价格数据 =====================\n",
    "\n",
    "def preprocess_price_data(df):\n",
    "    \"\"\"\n",
    "    输入：原始 DataFrame\n",
    "    期望至少包含：\n",
    "      - 'start_price'    起始价格\n",
    "      - 'price_series'   价格路径（类似 \"[100, 101, 102]\" 这种字符串）\n",
    "    输出：\n",
    "      - 新的 df，包含：\n",
    "         'S_0'           起始价格（数值）\n",
    "         'price_series'  每行都是 numpy.array([p0, p1, ...])\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 起始价格转成数值，重命名为 S_0\n",
    "    df[\"start_price\"] = pd.to_numeric(df[\"start_price\"], errors=\"coerce\")\n",
    "    df = df.rename(columns={\"start_price\": \"S_0\"})\n",
    "\n",
    "    def parse_series(x):\n",
    "        # 如果是字符串 \"[100, 101, 102]\"，用 eval 解析\n",
    "        if isinstance(x, str):\n",
    "            arr = eval(x)\n",
    "            return np.array(arr, dtype=np.float32)\n",
    "        # 如果本来就是 list/array，就直接转\n",
    "        elif isinstance(x, (list, np.ndarray)):\n",
    "            return np.array(x, dtype=np.float32)\n",
    "        else:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "    df[\"price_series\"] = df[\"price_series\"].apply(parse_series)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===================== 4. 把价格路径 → 收益率序列 + mask =====================\n",
    "\n",
    "def build_sequences_and_masks(df, config):\n",
    "    \"\"\"\n",
    "    从 df['price_series'] 生成：\n",
    "      - transformed_sequence：长度固定的收益率序列\n",
    "      - validity_mask：同长度的 mask，1=真实数据，0=补零\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    seq_len = config[\"input_sequence_length\"]\n",
    "    vol_scale = float(config[\"volatility_scale\"])\n",
    "\n",
    "    def process_one(price_series):\n",
    "        prices = np.asarray(price_series, dtype=np.float32)\n",
    "        target = np.zeros(seq_len, dtype=np.float32)\n",
    "        mask = np.zeros(seq_len, dtype=np.float32)\n",
    "\n",
    "        if len(prices) < 2:\n",
    "            # 只有起始标记\n",
    "            target[0] = 1.0\n",
    "            mask[0] = 1.0\n",
    "            return target, mask\n",
    "\n",
    "        # 对数收益率\n",
    "        log_returns = np.diff(np.log(prices))\n",
    "        scaled = log_returns / vol_scale\n",
    "\n",
    "        # 第0位作为起始标记\n",
    "        target[0] = 1.0\n",
    "        mask[0] = 1.0\n",
    "\n",
    "        max_n = min(len(scaled), seq_len - 1)\n",
    "        target[1:1 + max_n] = scaled[:max_n]\n",
    "        mask[1:1 + max_n] = 1.0\n",
    "        return target, mask\n",
    "\n",
    "    tmp = df[\"price_series\"].apply(process_one)\n",
    "    df[\"transformed_sequence\"] = tmp.apply(lambda x: x[0])\n",
    "    df[\"validity_mask\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===================== 5. 构造条件特征矩阵 =====================\n",
    "\n",
    "def build_condition_array(df, config, need_fit_scaler=True, scaler=None):\n",
    "    \"\"\"\n",
    "    构造条件特征矩阵 (N, D)，D 大致包括：\n",
    "        - S_0 / base_trading_days\n",
    "        - volatility\n",
    "        - risk_free_rate\n",
    "        - contract_calendar_days / 365\n",
    "        - actual_trading_days / base_trading_days\n",
    "        - country_id（或对 country 编码）\n",
    "        - index_id（或对 asset_underlying 编码）\n",
    "    返回：\n",
    "        - cond_scaled：标准化后的条件特征\n",
    "        - scaler：拟合好的 scaler（只在 need_fit_scaler=True 时重新拟合）\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    base_days = float(config[\"base_trading_days\"])\n",
    "\n",
    "    prices = df[\"S_0\"].astype(float).values / base_days\n",
    "    contract_days = df[\"contract_calendar_days\"].astype(float).values / 365.0\n",
    "    trading_days = df[\"actual_trading_days\"].astype(float).values / base_days\n",
    "    vol = df[\"volatility\"].astype(float).values\n",
    "    rf = df[\"risk_free_rate\"].astype(float).values\n",
    "\n",
    "    # 国家 ID\n",
    "    if \"country_id\" in df.columns:\n",
    "        country_id = df[\"country_id\"].astype(int).values\n",
    "    elif \"country\" in df.columns:\n",
    "        country_id = encode_to_ids(df[\"country\"])\n",
    "    else:\n",
    "        country_id = np.zeros(len(df), dtype=np.int32)\n",
    "\n",
    "    # 指数 ID\n",
    "    if \"index_id\" in df.columns:\n",
    "        index_id = df[\"index_id\"].astype(int).values\n",
    "    elif \"asset_underlying\" in df.columns:\n",
    "        index_id = encode_to_ids(df[\"asset_underlying\"])\n",
    "    else:\n",
    "        index_id = np.zeros(len(df), dtype=np.int32)\n",
    "\n",
    "    cond = np.column_stack([\n",
    "        prices,\n",
    "        vol,\n",
    "        rf,\n",
    "        contract_days,\n",
    "        trading_days / (contract_days + 1e-6),  # 防止除0\n",
    "        country_id,\n",
    "        index_id,\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    if need_fit_scaler:\n",
    "        cond_scaled, scaler = fit_scaler(cond, outlier_threshold=3.0)\n",
    "    else:\n",
    "        cond_scaled = transform_with_scaler(cond, scaler)\n",
    "\n",
    "    return cond_scaled, scaler\n",
    "\n",
    "\n",
    "# ===================== 6. 从预测结果还原价格路径（可选） =====================\n",
    "\n",
    "def recover_price_path(x_sample, y_pred, scaler, config):\n",
    "    \"\"\"\n",
    "    x_sample: 条件特征的一行（和 cond_scaled 中一行对应）\n",
    "    y_pred:   模型预测的一条序列，形状类似 (seq_len,) 或 (1, seq_len)\n",
    "    返回：还原后的价格路径（numpy 数组）\n",
    "    \"\"\"\n",
    "    x_sample = np.asarray(x_sample, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # 先反标准化，回到构造 cond 之前的空间\n",
    "    x_unscaled = inverse_transform(x_sample, scaler)\n",
    "\n",
    "    # 第0列对应的是 price_feature = S_0 / base_trading_days\n",
    "    norm_price = x_unscaled[0, 0]\n",
    "    start_price = norm_price * float(config[\"base_trading_days\"])\n",
    "\n",
    "    # y_pred：第0位是起始标记，从第1位开始是收益率\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float32).ravel()\n",
    "    returns_scaled = y_pred[1:]\n",
    "    valid_returns = returns_scaled[returns_scaled != 0.0]\n",
    "    log_returns = valid_returns * float(config[\"volatility_scale\"])\n",
    "\n",
    "    # 对 log_returns 做累加，还原价格路径\n",
    "    log_prices = [np.log(start_price)]\n",
    "    for r in log_returns:\n",
    "        log_prices.append(log_prices[-1] + r)\n",
    "    log_prices = np.array(log_prices, dtype=np.float32)\n",
    "    prices = np.exp(log_prices)\n",
    "    return prices\n",
    "\n",
    "\n",
    "# ===================== 7. 一路算到 PyTorch 张量 =====================\n",
    "\n",
    "# 1) 处理价格数据\n",
    "data_after_price = preprocess_price_data(training_data_mock)\n",
    "\n",
    "# 2) 生成收益率序列和 mask\n",
    "data_with_seq = build_sequences_and_masks(data_after_price, config)\n",
    "\n",
    "# 3) 构造条件特征并做标准化（这里是训练集，所以拟合 scaler）\n",
    "cond_np, global_scaler = build_condition_array(\n",
    "    data_with_seq,\n",
    "    config,\n",
    "    need_fit_scaler=True,\n",
    "    scaler=None\n",
    ")\n",
    "\n",
    "# 4) 把目标序列和 mask 取出来，转成 numpy\n",
    "y_np = np.array(data_with_seq[\"transformed_sequence\"].tolist(), dtype=np.float32)\n",
    "mask_np = np.array(data_with_seq[\"validity_mask\"].tolist(), dtype=np.float32)\n",
    "\n",
    "# 5) 调整形状：y 和 mask 变成 (N, 1, seq_len)\n",
    "y_np = y_np.reshape(len(y_np), 1, -1)\n",
    "mask_np = mask_np.reshape(len(mask_np), 1, -1)\n",
    "\n",
    "# 6) 转成 PyTorch 张量\n",
    "X_t = torch.tensor(cond_np, dtype=torch.float32)    # (N, D)\n",
    "y_t = torch.tensor(y_np, dtype=torch.float32)       # (N, 1, seq_len)\n",
    "mask_t = torch.tensor(mask_np, dtype=torch.float32) # (N, 1, seq_len)\n",
    "\n",
    "print(\"数据准备完成：\")\n",
    "print(\"X_t 形状:\", X_t.shape)\n",
    "print(\"y_t 形状:\", y_t.shape)\n",
    "print(\"mask_t 形状:\", mask_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcb7bbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.04772186,  0.13432503, -0.23103714,  0.3653717 ,\n",
       "        0.20168304,  0.1579094 , -0.10186195,  0.21384239,  0.07678986,\n",
       "       -0.04124641, -0.06207466, -0.1190567 , -0.01635551,  0.17990112,\n",
       "       -0.00181198,  0.00110626, -0.1928997 , -0.08019447,  0.12433052,\n",
       "        0.13587952,  0.08735657,  0.16573906,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_seq[\"transformed_sequence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45f068b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e5df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628f970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlpm_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
